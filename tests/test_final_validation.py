#!/usr/bin/env python3
"""
Final validation test for the stream status fix.
This test demonstrates the before/after behavior and validates the complete fix.
"""

import sys
import os
from unittest.mock import patch

# Add app to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))


def test_complete_fix_validation():
    """End-to-end test showing the fix solves the problem."""
    print("\nğŸ”§ FINAL VALIDATION: Complete Fix Test")
    print("=" * 70)
    
    from app.services.state import state as global_state
    from app.models.schemas import StreamStartedEvent, StreamEndedEvent, EngineAddress, StreamKey, SessionInfo
    from app.main import app
    from fastapi.testclient import TestClient
    
    # Clear state
    global_state.clear_state()
    
    # Create test client
    client = TestClient(app)
    
    print("\nğŸ“ Scenario: User has 2 streams, ends 1, checks engine")
    print("-" * 70)
    
    with patch('app.services.state.SessionLocal'):
        # Step 1: Start 2 streams
        print("\n1ï¸âƒ£  Starting 2 streams on engine 'my_engine'...")
        for i in [1, 2]:
            evt = StreamStartedEvent(
                container_id="my_engine",
                engine=EngineAddress(host="192.168.1.100", port=8080),
                stream=StreamKey(key_type="infohash", key=f"hash_{i}"),
                session=SessionInfo(
                    playback_session_id=f"session_{i}",
                    stat_url=f"http://192.168.1.100:8080/stat_{i}",
                    command_url=f"http://192.168.1.100:8080/cmd_{i}",
                    is_live=1
                ),
                labels={"stream_id": f"channel_{i}"}
            )
            global_state.on_stream_started(evt)
        
        # Verify engine has 2 streams
        engine = global_state.get_engine("my_engine")
        print(f"   âœ… Engine created with {len(engine.streams)} active streams")
        
        # Step 2: Check engine endpoint
        print("\n2ï¸âƒ£  Calling GET /engines/my_engine...")
        response = client.get("/engines/my_engine")
        data = response.json()
        print(f"   âœ… Endpoint returned {len(data['streams'])} streams:")
        for stream in data['streams']:
            print(f"      - {stream['id']} (status: {stream['status']})")
        
        assert len(data['streams']) == 2, "Should have 2 active streams"
        
        # Step 3: End one stream
        print("\n3ï¸âƒ£  Ending stream 'channel_1'...")
        evt_ended = StreamEndedEvent(
            container_id="my_engine",
            stream_id="channel_1",
            reason="user_stopped"
        )
        result = global_state.on_stream_ended(evt_ended)
        print(f"   âœ… Stream ended: {result.id}")
        
        # Verify engine now has 1 stream
        engine = global_state.get_engine("my_engine")
        print(f"   âœ… Engine now has {len(engine.streams)} active stream")
        
        # Step 4: Check engine endpoint again
        print("\n4ï¸âƒ£  Calling GET /engines/my_engine again...")
        response = client.get("/engines/my_engine")
        data = response.json()
        print(f"   âœ… Endpoint returned {len(data['streams'])} streams:")
        for stream in data['streams']:
            print(f"      - {stream['id']} (status: {stream['status']})")
        
        # CRITICAL CHECK: Should only show 1 active stream, not both
        assert len(data['streams']) == 1, "Should have 1 active stream"
        assert data['streams'][0]['id'] == 'channel_2', "Should return the still-active stream"
        assert data['streams'][0]['status'] == 'started', "Stream should have status 'started'"
        
        print("\nâœ… FIX CONFIRMED: Endpoint correctly shows only active streams!")
        
        # Step 5: Verify ended stream is removed from memory
        print("\n5ï¸âƒ£  Checking state consistency...")
        all_streams = global_state.list_streams(container_id="my_engine")
        print(f"   âœ… Total streams in state: {len(all_streams)} (ended streams removed immediately)")
        
        started_streams = global_state.list_streams(status="started", container_id="my_engine")
        print(f"   âœ… Active streams in state: {len(started_streams)}")
        
        ended_streams = global_state.list_streams(status="ended", container_id="my_engine")
        print(f"   âœ… Ended streams in state: {len(ended_streams)} (removed immediately)")
        
        assert len(all_streams) == 1, "State should only have active stream (ended removed)"
        assert len(started_streams) == 1, "State should show 1 active"
        assert len(ended_streams) == 0, "State should show 0 ended (removed)"
        
        # Step 6: End the last stream
        print("\n6ï¸âƒ£  Ending last stream 'channel_2'...")
        evt_ended_2 = StreamEndedEvent(
            container_id="my_engine",
            stream_id="channel_2",
            reason="user_stopped"
        )
        global_state.on_stream_ended(evt_ended_2)
        
        # Verify engine has no streams
        engine = global_state.get_engine("my_engine")
        print(f"   âœ… Engine now has {len(engine.streams)} active streams")
        
        # Step 7: Final endpoint check
        print("\n7ï¸âƒ£  Final endpoint check...")
        response = client.get("/engines/my_engine")
        data = response.json()
        print(f"   âœ… Endpoint returned {len(data['streams'])} streams")
        
        assert len(data['streams']) == 0, "Should have no active streams"
        print("\nâœ… PERFECT: Engine shows 0 streams when all have ended!")
    
    print("\n" + "=" * 70)
    print("ğŸ‰ FINAL VALIDATION PASSED!")
    print("\nğŸ“Š Summary:")
    print("   âœ… Fixed issue: ended streams are immediately removed from memory")
    print("   âœ… /streams endpoint only shows active streams")
    print("   âœ… /engines/{container_id} correctly displays only active streams")
    print("   âœ… Historical data preserved in database for analytics")
    return True


def test_bug_reproduction_before_fix():
    """Document what the bug looked like before the fix."""
    print("\nğŸ“š DOCUMENTATION: What the bug looked like")
    print("=" * 70)
    
    from app.services.state import State
    from app.models.schemas import StreamStartedEvent, StreamEndedEvent, EngineAddress, StreamKey, SessionInfo
    
    state = State()
    
    print("\nâŒ BEFORE FIX:")
    print("   User starts stream â†’ Engine shows 1 stream âœ“")
    print("   User stops stream â†’ Engine STILL shows 1 stream âœ—")
    print("   Problem: Ended streams remained in memory")
    print("   This caused ALL streams (started + ended) to appear in endpoints")
    
    print("\nâœ… AFTER FIX:")
    print("   User starts stream â†’ Engine shows 1 stream âœ“")
    print("   User stops stream â†’ Engine shows 0 streams âœ“")
    print("   Solution: Ended streams are immediately removed from memory")
    print("   This ensures only active streams appear in endpoints")
    
    with patch('app.services.state.SessionLocal'):
        # Demonstrate the state behavior
        print("\nğŸ”¬ Demonstrating state behavior:")
        
        # Start a stream
        evt = StreamStartedEvent(
            container_id="demo_engine",
            engine=EngineAddress(host="127.0.0.1", port=8080),
            stream=StreamKey(key_type="content_id", key="demo_content"),
            session=SessionInfo(
                playback_session_id="demo_session",
                stat_url="http://127.0.0.1:8080/stat",
                command_url="http://127.0.0.1:8080/cmd",
                is_live=1
            ),
            labels={"stream_id": "demo_stream"}
        )
        state.on_stream_started(evt)
        print(f"   Started stream: demo_stream")
        
        # End the stream
        evt_ended = StreamEndedEvent(
            container_id="demo_engine",
            stream_id="demo_stream",
            reason="demo"
        )
        state.on_stream_ended(evt_ended)
        print(f"   Ended stream: demo_stream")
        
        # Show the difference
        all_streams = state.list_streams(container_id="demo_engine")
        started_streams = state.list_streams(status="started", container_id="demo_engine")
        
        print(f"\n   list_streams(container_id) â†’ {len(all_streams)} streams (NEW behavior: ended removed)")
        print(f"   list_streams(status='started', container_id) â†’ {len(started_streams)} streams (same result)")
        
        print("\n   The fix ensures ended streams are immediately removed from memory")
    
    print("\n" + "=" * 70)
    return True


if __name__ == "__main__":
    try:
        test_complete_fix_validation()
        test_bug_reproduction_before_fix()
        
        print("\n" + "=" * 70)
        print("âœ… ALL VALIDATIONS PASSED!")
        print("\nğŸš€ Ready for production!")
        sys.exit(0)
    except AssertionError as e:
        print(f"\nâŒ Validation failed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
